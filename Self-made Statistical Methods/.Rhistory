#data_test <- train[fold == i, ]
data_train <- train %>% filter(fold != i)
data_test <- train %>% filter(fold == i)
# Split true class value of training data into train and test
cl_train <- cl[fold != i]
cl_test <- cl[fold == i]
# store knn output into a variable
output <- class::knn(train = data_train, test = data_test, cl = cl_train, k = k_nn)
# Calculate the misclassification rate
misclassification[i] <- sum(output != cl_test)/length(cl_test)
}
# Prediction output class
class <- class::knn(train = train, test = train, cl = cl, k = k_nn)
# Cross-validation misclassification error
cv_err <- mean(misclassification)
# Return the list of desired objects
return(list("class" = class, "cv_err" = cv_err))
}
# Drop the na values from the penguins data frame
penguins <- na.omit(penguins)
# Perform k nearest neighbor with 5 fold and 1-nearest neighbor and 5-nearest neighbor
neighbor_1 <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
View(penguins)
# Drop the na values from the penguins data frame
penguins <- na.omit(penguins)
# Perform k nearest neighbor with 5 fold and 1-nearest neighbor and 5-nearest neighbor
neighbor_1 <- my_knn_cv(penguins[[, 3:6]], penguins$species, 1, 5)
# Drop the na values from the penguins data frame
penguins <- na.omit(penguins)
# Perform k nearest neighbor with 5 fold and 1-nearest neighbor and 5-nearest neighbor
neighbor_1 <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
# Drop the na values from the penguins data frame
penguins <- na.omit(penguins)
# Perform k nearest neighbor with 5 fold and 1-nearest neighbor and 5-nearest neighbor
neighbor_1 <- my_knn_cv(penguins(, 3:6), penguins$species, 1, 5)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
# generate data
set.seed(302)
n <- 30
x <- sort(runif(n, -3, 3))
y <- 2*x + 2*rnorm(n)
x_test <- sort(runif(n, -3, 3))
y_test <- 2*x_test + 2*rnorm(n)
df_train <- data.frame("x" = x, "y" = y)
df_test <- data.frame("x" = x_test, "y" = y_test)
# store a theme
my_theme <- theme_bw(base_size = 16) +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
plot.subtitle = element_text(hjust = 0.5))
# generate plots
g_train <- ggplot(df_train, aes(x = x, y = y)) + geom_point() +
xlim(-3, 3) + ylim(min(y, y_test), max(y, y_test)) +
labs(title = "Training Data") + my_theme
g_test <- ggplot(df_test, aes(x = x, y = y)) + geom_point() +
xlim(-3, 3) + ylim(min(y, y_test), max(y, y_test)) +
labs(title = "Test Data") + my_theme
g_train
g_test
# Fit 1-10 degree polynomial linear regression model with y as the response and x as the explanatory variable
lm_1 <- lm(y ~ x, data = df_train)
lm_2 <- lm(y ~ poly(x, 2), data = df_train)
lm_3 <- lm(y ~ poly(x, 3), data = df_train)
lm_4 <- lm(y ~ poly(x, 4), data = df_train)
lm_5 <- lm(y ~ poly(x, 5), data = df_train)
lm_6 <- lm(y ~ poly(x, 6), data = df_train)
lm_7 <- lm(y ~ poly(x, 7), data = df_train)
lm_8 <- lm(y ~ poly(x, 8), data = df_train)
lm_9 <- lm(y ~ poly(x, 9), data = df_train)
lm_10 <- lm(y ~ poly(x, 10), data = df_train)
# Find the predicted y value for the training set
yhat_train_1 <- predict(lm_1)
yhat_train_2 <- predict(lm_2)
yhat_train_3 <- predict(lm_3)
yhat_train_4 <- predict(lm_4)
yhat_train_5 <- predict(lm_5)
yhat_train_6 <- predict(lm_6)
yhat_train_7 <- predict(lm_7)
yhat_train_8 <- predict(lm_8)
yhat_train_9 <- predict(lm_9)
yhat_train_10 <- predict(lm_10)
# Create a dataframe to store the predicted y train values
yhat_train <- data.frame(yhat_train_1, yhat_train_2, yhat_train_3, yhat_train_4, yhat_train_5, yhat_train_6, yhat_train_7, yhat_train_8, yhat_train_9, yhat_train_10)
# Find the predicted y value for the testing set
yhat_test_1 <- predict(lm_1, data.frame(x = df_test$x))
yhat_test_2 <- predict(lm_2, data.frame(x = df_test$x))
yhat_test_3 <- predict(lm_3, data.frame(x = df_test$x))
yhat_test_4 <- predict(lm_4, data.frame(x = df_test$x))
yhat_test_5 <- predict(lm_5, data.frame(x = df_test$x))
yhat_test_6 <- predict(lm_6, data.frame(x = df_test$x))
yhat_test_7 <- predict(lm_7, data.frame(x = df_test$x))
yhat_test_8 <- predict(lm_8, data.frame(x = df_test$x))
yhat_test_9 <- predict(lm_9, data.frame(x = df_test$x))
yhat_test_10 <- predict(lm_10, data.frame(x = df_test$x))
# Create a dataframe to store the predicted y test values
yhat_test <- data.frame(yhat_test_1, yhat_test_2, yhat_test_3, yhat_test_4, yhat_test_5, yhat_test_6, yhat_test_7, yhat_test_8, yhat_test_9, yhat_test_10)
# Create two lists to store the train errors and test errors
train_error <- list()
test_error <- list()
# Compute the training error and test error of each model
for (i in 1:10) {
train_error[i] <- mean((df_train$y - yhat_train[, i])^2)
test_error[i] <- mean((df_test$y - yhat_test[, i])^2)
}
# Import library kableExtra to display the table after knitting
library(kableExtra)
# Create an empty list to store the number of k-s
lm_list <- list()
# Put 1-10 to the list
for (i in 1:10){
lm_list[i] <- paste(i)
}
# Create a dataframe that combines the number of k-s, train error, and test error
train_test_error <- do.call(rbind, Map(data.frame,
"Number of k" = lm_list,
"Train Error" = train_error,
"Test Error" = test_error))
# Present the table
kable_styling(kable(train_test_error))
# Add split to the training and test data
df_train$split <- rep("Training", 30)
df_test$split <- rep("Test", 30)
# Combine two datasets into one
data <- rbind(df_train, df_test)
# Compute the fitting line of the degree 10 model (the chosen model based on training error)
x_fit <- data.frame(x = seq(min(data$x), max(data$x), length = 100))
line_fit_10 <- data.frame(x = x_fit, y = predict(lm_10, newdata = x_fit))
# Plot the chosen model based on training error
g_split10 <- ggplot(data, aes(x = x, y = y, color = split)) +
geom_point() +
labs(title = "Chosen Linear Model Based on Train Error (k = 10)") +
labs(subtitle = paste("Degree 10 Test error:", round(test_error[[10]], 3))) +
geom_line(data = line_fit_10, aes(y = y, x = x), col = "black", lwd = 1.5) +
my_theme
# Display graph
g_split10
# Compute the fitting line of the degree 1 model (the chosen model based on test error)
line_fit_1 <- data.frame(x = x_fit, y = predict(lm_1, newdata = x_fit))
# Plot the chosen model based on test error
g_split1 <- ggplot(data, aes(x = x, y = y, color = split)) +
geom_point() +
labs(title = "Chosen Linear Model Based on Test Error (k = 1)") +
labs(subtitle = paste("Degree 1 Test error:", round(test_error[[1]], 3))) +
geom_line(data = line_fit_1, aes(y = y, x = x), col = "black", lwd = 1.5) +
my_theme
# Display graph
g_split1
library(palmerpenguins)
data("penguins")
#' k-Nearest Neighbors Cross-Validation Function
#'
#' This function predicts output from existed variables by using k-nearest neighbors cross-validation
#'
#' @param train input data frame.
#' @param cl true class value of training data.
#' @param k_nn integer representing the number of neighbors.
#' @param k_cv integer representing the number of folds.
#' @return return a list of objects:
#' \item{class}{a vector of the predicted class Y hat for all observations}
#' \item{df}{a numeric with the cross-validation misclassification error}
my_knn_cv <- function(train, cl, k_nn, k_cv) {
# Define a variable fold that randomly assigns observations to folds with equal probability
fold <- sample(rep(1:k_cv, length = nrow(train)))
# Store the misclassification rate
misclassification <- rep(NA, k_cv)
for (i in 1:k_cv) {
# Split input data frame to train and test
#data_train <- train[fold != i, ]
#data_test <- train[fold == i, ]
data_train <- train %>% filter(fold != i)
data_test <- train %>% filter(fold == i)
# Split true class value of training data into train and test
cl_train <- cl[fold != i]
cl_test <- cl[fold == i]
# store knn output into a variable
output <- class::knn(train = data_train, test = data_test, cl = cl_train, k = k_nn)
# Calculate the misclassification rate
misclassification[i] <- sum(output != cl_test)/length(cl_test)
}
# Prediction output class
class <- class::knn(train = train, test = train, cl = cl, k = k_nn)
# Cross-validation misclassification error
cv_err <- mean(misclassification)
# Return the list of desired objects
return(list("class" = class, "cv_err" = cv_err))
}
# Drop the na values from the penguins data frame
penguins <- na.omit(penguins)
# Perform k nearest neighbor with 5 fold and 1-nearest neighbor and 5-nearest neighbor
neighbor_1 <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
#' k-Nearest Neighbors Cross-Validation Function
#'
#' This function predicts output from existed variables by using k-nearest neighbors cross-validation
#'
#' @param train input data frame.
#' @param cl true class value of training data.
#' @param k_nn integer representing the number of neighbors.
#' @param k_cv integer representing the number of folds.
#' @return return a list of objects:
#' \item{class}{a vector of the predicted class Y hat for all observations}
#' \item{df}{a numeric with the cross-validation misclassification error}
my_knn_cv <- function(train, cl, k_nn, k_cv) {
# Define a variable fold that randomly assigns observations to folds with equal probability
fold <- sample(rep(1:k_cv, length = nrow(train)))
# Store the misclassification rate
misclassification <- rep(NA, k_cv)
for (i in 1:k_cv) {
# Split input data frame to train and test
data_train <- train[fold != i, ]
data_test <- train[fold == i, ]
#data_train <- train %>% filter(fold != i)
#data_test <- train %>% filter(fold == i)
# Split true class value of training data into train and test
cl_train <- cl[fold != i]
cl_test <- cl[fold == i]
# store knn output into a variable
output <- class::knn(train = data_train, test = data_test, cl = cl_train, k = k_nn)
# Calculate the misclassification rate
misclassification[i] <- sum(output != cl_test)/length(cl_test)
}
# Prediction output class
class <- class::knn(train = train, test = train, cl = cl, k = k_nn)
# Cross-validation misclassification error
cv_err <- mean(misclassification)
# Return the list of desired objects
return(list("class" = class, "cv_err" = cv_err))
}
# Drop the na values from the penguins data frame
penguins <- na.omit(penguins)
# Perform k nearest neighbor with 5 fold and 1-nearest neighbor and 5-nearest neighbor
neighbor_1 <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
neighbor_5 <- my_knn_cv(penguins[, 3:6], penguins$species, 5, 5)
# Compute the training error
training_error <- list()
training_error[[1]] <- mean(neighbor_1[[1]] != penguins$species)
training_error[[2]] <- mean(neighbor_5[[1]] != penguins$species)
# Put the information to a table
cv_table <- data.frame(knn = c(1, 5),
cv = c(neighbor_1[[2]], neighbor_5[[2]]),
training_error = c(training_error[[1]], training_error[[2]]))
kable_styling(kable(cv_table))
#' k-Nearest Neighbors Cross-Validation Function
#'
#' This function predicts output from existed variables by using k-nearest neighbors cross-validation
#'
#' @param train input data frame.
#' @param cl true class value of training data.
#' @param k_nn integer representing the number of neighbors.
#' @param k_cv integer representing the number of folds.
#' @return return a list of objects:
#' \item{class}{a vector of the predicted class Y hat for all observations}
#' \item{df}{a numeric with the cross-validation misclassification error}
my_knn_cv <- function(train, cl, k_nn, k_cv) {
# Define a variable fold that randomly assigns observations to folds with equal probability
fold <- sample(rep(1:k_cv, length = nrow(train)))
# Store the misclassification rate
misclassification <- rep(NA, k_cv)
for (i in 1:k_cv) {
# Split input data frame to train and test
#data_train <- train[fold != i, ]
#data_test <- train[fold == i, ]
data_train <- train %>% filter(fold != i)
data_test <- train %>% filter(fold == i)
# Split true class value of training data into train and test
cl_train <- cl[fold != i]
cl_test <- cl[fold == i]
# store knn output into a variable
output <- knn(train = data_train, test = data_test, cl = cl_train, k = k_nn)
# Calculate the misclassification rate
misclassification[i] <- sum(output != cl_test)/length(cl_test)
}
# Prediction output class
class <- knn(train = train, test = train, cl = cl, k = k_nn)
# Cross-validation misclassification error
cv_err <- mean(misclassification)
# Return the list of desired objects
return(list("class" = class, "cv_err" = cv_err))
}
# Drop the na values from the penguins data frame
penguins <- na.omit(penguins)
# Perform k nearest neighbor with 5 fold and 1-nearest neighbor and 5-nearest neighbor
neighbor_1 <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
#' k-Nearest Neighbors Cross-Validation Function
#'
#' This function predicts output from existed variables by using k-nearest neighbors cross-validation
#'
#' @param train input data frame.
#' @param cl true class value of training data.
#' @param k_nn integer representing the number of neighbors.
#' @param k_cv integer representing the number of folds.
#' @return return a list of objects:
#' \item{class}{a vector of the predicted class Y hat for all observations}
#' \item{df}{a numeric with the cross-validation misclassification error}
my_knn_cv <- function(train, cl, k_nn, k_cv) {
# Define a variable fold that randomly assigns observations to folds with equal probability
fold <- sample(rep(1:k_cv, length = nrow(train)))
# Store the misclassification rate
misclassification <- rep(NA, k_cv)
for (i in 1:k_cv) {
# Split input data frame to train and test
data_train <- train[fold != i, ]
data_test <- train[fold == i, ]
#data_train <- train %>% filter(fold != i)
#data_test <- train %>% filter(fold == i)
# Split true class value of training data into train and test
cl_train <- cl[fold != i]
cl_test <- cl[fold == i]
# store knn output into a variable
output <- class::knn(train = data_train, test = data_test, cl = cl_train, k = k_nn)
# Calculate the misclassification rate
misclassification[i] <- sum(output != cl_test)/length(cl_test)
}
# Prediction output class
class <- class::knn(train = train, test = train, cl = cl, k = k_nn)
# Cross-validation misclassification error
cv_err <- mean(misclassification)
# Return the list of desired objects
return(list("class" = class, "cv_err" = cv_err))
}
# Drop the na values from the penguins data frame
penguins <- na.omit(penguins)
# Perform k nearest neighbor with 5 fold and 1-nearest neighbor and 5-nearest neighbor
neighbor_1 <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
neighbor_5 <- my_knn_cv(penguins[, 3:6], penguins$species, 5, 5)
# Compute the training error
training_error <- list()
training_error[[1]] <- mean(neighbor_1[[1]] != penguins$species)
training_error[[2]] <- mean(neighbor_5[[1]] != penguins$species)
# Put the information to a table
cv_table <- data.frame(knn = c(1, 5),
cv = c(neighbor_1[[2]], neighbor_5[[2]]),
training_error = c(training_error[[1]], training_error[[2]]))
kable_styling(kable(cv_table))
#' k-Nearest Neighbors Cross-Validation Function
#'
#' This function predicts output from existed variables by using k-nearest neighbors cross-validation
#'
#' @param train input data frame.
#' @param cl true class value of training data.
#' @param k_nn integer representing the number of neighbors.
#' @param k_cv integer representing the number of folds.
#' @return return a list of objects:
#' \item{class}{a vector of the predicted class Y hat for all observations}
#' \item{df}{a numeric with the cross-validation misclassification error}
my_knn_cv <- function(train, cl, k_nn, k_cv) {
# Define a variable fold that randomly assigns observations to folds with equal probability
fold <- sample(rep(1:k_cv, length = nrow(train)))
# Store the misclassification rate
misclassification <- rep(NA, k_cv)
for (i in 1:k_cv) {
# Split input data frame to train and test
#data_train <- train[fold != i, ]
#data_test <- train[fold == i, ]
data_train <- train %>% filter(fold != i)
data_test <- train %>% filter(fold == i)
# Split true class value of training data into train and test
cl_train <- cl[fold != i]
cl_test <- cl[fold == i]
# store knn output into a variable
output <- class::knn(train = data_train, test = data_test, cl = cl_train, k = k_nn)
# Calculate the misclassification rate
misclassification[i] <- sum(output != cl_test)/length(cl_test)
}
# Prediction output class
class <- class::knn(train = train, test = train, cl = cl, k = k_nn)
# Cross-validation misclassification error
cv_err <- mean(misclassification)
# Return the list of desired objects
return(list("class" = class, "cv_err" = cv_err))
}
# Drop the na values from the penguins data frame
penguins <- na.omit(penguins)
# Perform k nearest neighbor with 5 fold and 1-nearest neighbor and 5-nearest neighbor
neighbor_1 <- my_knn_cv(penguins[, 3:6], penguins$species, 1, 5)
View(penguins)
library(rlang)
remove.packages("rlang", lib="~/R/win-library/4.1")
install.packages("rlang")
install.packages("rlang")
detach("package:rlang", unload = TRUE)
detach("package:rlang", unload = TRUE)
install.packages("rlang")
setwd("C:/Users/pauls/Desktop/stat302/projects/Project3")
devtools::document()
devtools::chekc()
devtools
devtools::check()
devtools::install()
library(Project3)
data("my_penguins")
#load("C:/Users/pauls/Desktop/stat302/projects/Project3/data/my_penguins.rda")
my_penguins <- na.omit(my_penguins)
#source("C:/Users/pauls/Desktop/stat302/projects/Project3/R/my_t.test.R")
#source("C:/Users/pauls/Desktop/stat302/projects/Project3/R/my_lm.R")
#source("C:/Users/pauls/Desktop/stat302/projects/Project3/R/my_knn_cv.R")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
my_t.test(my_penguins$body_mass_g, mu = 4000, alternative = "less")
my_lm(body_mass_g ~ flipper_length_mm, data = my_penguins)
knn_num <- c(1:10)
training_error <- c(1:10)
cv_error <- c(1:10)
for(i in 1:10) {
neighbors <- my_knn_cv(my_penguins[ , 3:6], my_penguins$species, i, 5)
training_error[i] <- mean(neighbors[[1]] != my_penguins$species)
cv_error[i] <- mean(neighbors[[2]])
}
results <- data.frame("knn" = knn_num, "training_error" = training_error, "cv_error" = cv_error)
results
View(my_penguins)
penguins <- filter(my_penguins, species == "Adelie")
library(Project3)
data("my_penguins")
#load("C:/Users/pauls/Desktop/stat302/projects/Project3/data/my_penguins.rda")
my_penguins <- na.omit(my_penguins)
#source("C:/Users/pauls/Desktop/stat302/projects/Project3/R/my_t.test.R")
#source("C:/Users/pauls/Desktop/stat302/projects/Project3/R/my_lm.R")
#source("C:/Users/pauls/Desktop/stat302/projects/Project3/R/my_knn_cv.R")
my_t.test(my_penguins$body_mass_g, mu = 4000, alternative = "less")
penguins <- filter(my_penguins, species == "Adelie")
penguins <- filter(my_penguins, species == "Adelie")
View(my_penguins)
penguins <- dplyr::filter(my_penguins, species == "Adelie")
my_t.test(my_penguins$body_mass_g, mu = 4000, alternative = "less")
penguins <- dplyr::filter(my_penguins, species == "Adelie")
my_t.test(penguins$body_mass_g, mu = 4000, alternative = "less")
View(penguins)
my_lm(body_mass_g ~ flipper_length_mm, data = my_penguins)
knn_num <- c(1:10)
training_error <- c(1:10)
cv_error <- c(1:10)
for(i in 1:10) {
neighbors <- my_knn_cv(my_penguins[ , 3:6], my_penguins$species, i, 5)
training_error[i] <- mean(neighbors[[1]] != my_penguins$species)
cv_error[i] <- mean(neighbors[[2]])
}
results <- data.frame("knn" = knn_num, "training_error" = training_error, "cv_error" = cv_error)
results
devtools::install()
remove.packages("fansi", lib="~/R/win-library/4.1")
install.packages("fansi")
install.packages("fansi")
install.packages(fansi)
install.packages("fansi")
remove.packages("magrittr", lib="~/R/win-library/4.1")
install.packages("magrittr")
setwd("C:/Users/pauls/Desktop/stat302/projects/Project3")
devtools::check()
# Import the created package
library(Project3)
# Load the data my_penguins dataset
data("my_penguins")
# Remove all the NA values from the my_penguins dataset to avoid errors
my_penguins <- na.omit(my_penguins)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# Import the created package
library(Project3)
# Load the data my_penguins dataset
data("my_penguins")
# Remove all the NA values from the my_penguins dataset to avoid errors
my_penguins <- na.omit(my_penguins)
# Filter to have only Adelie penguins in the dataset
penguins <- dplyr::filter(my_penguins, species == "Adelie")
# Compute the t test using alternative method "less"
my_t.test(penguins$body_mass_g, mu = 4000, alternative = "less")
# Compute the linear regression model using body_mass_g as dependent variable
# and flipper_length_mm as independent variable
my_lm(body_mass_g ~ flipper_length_mm, data = my_penguins)
# Create three vectors to store the results
knn_num <- c(1:10)
training_error <- c(1:10)
cv_error <- c(1:10)
# Create a for loop to go through different number of neighbors
for(i in 1:10) {
# Run k nearest neighbor through k nearest neighbor from 1 to 10
neighbors <- my_knn_cv(my_penguins[ , 3:6], my_penguins$species, i, 5)
# Compute the training error
training_error[i] <- mean(neighbors[[1]] != my_penguins$species)
# Compute the cross-validation error
cv_error[i] <- mean(neighbors[[2]])
}
# Store the results as a data frame
results <- data.frame("knn" = knn_num, "training_error" = training_error, "cv_error" = cv_error)
results
# Filter to have only Adelie penguins in the dataset
penguins <- dplyr::filter(my_penguins, species == "Adelie")
# Compute the t test using alternative method "less"
my_t.test(penguins$body_mass_g, mu = 4000, alternative = "less")
View(penguins)
View(penguins)
setwd("C:/Users/pauls/Desktop/stat302/projects/Project3")
devtools::document()
devtools::install()
setwd("C:/Users/pauls/Desktop/stat302/projects/Project3")
devtools::install()
library(Project3)
?my_lm
?my_knn_cv
?lm
devtools::document()
devtools::install()
setwd("C:/Users/pauls/Desktop/stat302/projects/Project3")
?my_lm
library(Project3)
?my_knn_cv
?my_t.test
devtools::check()
